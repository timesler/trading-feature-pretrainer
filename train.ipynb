{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from plotly import offline as py\n",
    "\n",
    "import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OHLCV and indicator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'data/indicators.csv',\n",
    "    index_col='sample_time',\n",
    "    parse_dates=True,\n",
    "    nrows=50001\n",
    ").iloc[:-1]\n",
    "ohlcv = data[[\n",
    "#     'open_m1',\n",
    "#     'high_m1',\n",
    "#     'low_m1',\n",
    "    'close_m1',\n",
    "#     'volume_tick_m1'\n",
    "]]\n",
    "indicators = data[[\n",
    "    'ema_close_12_m1',\n",
    "    'ema_close_16_m1',\n",
    "    'ema_close_26_m1',\n",
    "    'ema_close_50_m1',\n",
    "    'ema_close_60_m1',\n",
    "    'ema_close_100_m1',\n",
    "    'ema_close_200_m1',\n",
    "    'ema_close_240_m1',\n",
    "#     'ema_volume_tick_12_m1',\n",
    "#     'ema_volume_tick_26_m1',\n",
    "    'macd_close_12_26_m1',\n",
    "#     'macd_sig_close_12_26_9_m1',\n",
    "#     'macd_hist_close_12_26_9_m1',\n",
    "    'macd_close_16_100_m1',\n",
    "#     'macd_sig_close_16_100_2_m1',\n",
    "#     'macd_hist_close_16_100_2_m1',\n",
    "    'macd_close_60_240_m1',\n",
    "#     'macd_sig_close_60_240_10_m1',\n",
    "#     'macd_hist_close_60_240_10_m1',\n",
    "#     'macd_volume_tick_12_26_m1',\n",
    "#     'macd_sig_volume_tick_12_26_9_m1',\n",
    "#     'macd_hist_volume_tick_12_26_9_m1',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run EMA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(ohlcv.values.astype(np.float32))\n",
    "y = torch.tensor(indicators.values.astype(np.float32))\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "loader = DataLoader(dataset, batch_size=1024*64, num_workers=4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ema1 = modules.EMA(1, 8)\n",
    "        self.linear1 = nn.Linear(1 * 8, 11)\n",
    "    def forward(self, x, h0):\n",
    "        x, hn = self.ema1(x, h0)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear1(x)\n",
    "        return x, hn\n",
    "    \n",
    "encoder = FeatureEncoder()\n",
    "optmizer = optim.Adam(encoder.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100, loss: 2.272329807281494\n",
      "Epoch 2 of 100, loss: 2.020160675048828\n",
      "Epoch 3 of 100, loss: 1.789289951324463\n",
      "Epoch 4 of 100, loss: 1.577691912651062\n",
      "Epoch 5 of 100, loss: 1.38185453414917\n",
      "Epoch 6 of 100, loss: 1.2004659175872803\n",
      "Epoch 7 of 100, loss: 1.0351417064666748\n",
      "Epoch 8 of 100, loss: 0.887071430683136\n",
      "Epoch 9 of 100, loss: 0.7571144104003906\n",
      "Epoch 10 of 100, loss: 0.6459916830062866\n",
      "Epoch 11 of 100, loss: 0.5543099045753479\n",
      "Epoch 12 of 100, loss: 0.48248961567878723\n",
      "Epoch 13 of 100, loss: 0.4305798411369324\n",
      "Epoch 14 of 100, loss: 0.39791157841682434\n",
      "Epoch 15 of 100, loss: 0.38280463218688965\n",
      "Epoch 16 of 100, loss: 0.38317012786865234\n",
      "Epoch 17 of 100, loss: 0.3976632058620453\n",
      "Epoch 18 of 100, loss: 0.4184553325176239\n",
      "Epoch 19 of 100, loss: inf\n",
      "Epoch 20 of 100, loss: nan\n",
      "Epoch 21 of 100, loss: nan\n",
      "Epoch 22 of 100, loss: nan\n",
      "Epoch 23 of 100, loss: nan\n",
      "Epoch 24 of 100, loss: nan\n",
      "Epoch 25 of 100, loss: nan\n",
      "Epoch 26 of 100, loss: nan\n",
      "Epoch 27 of 100, loss: nan\n",
      "Epoch 28 of 100, loss: nan\n",
      "Epoch 29 of 100, loss: nan\n",
      "Epoch 30 of 100, loss: nan\n",
      "Epoch 31 of 100, loss: nan\n",
      "Epoch 32 of 100, loss: nan\n",
      "Epoch 33 of 100, loss: nan\n",
      "Epoch 34 of 100, loss: nan\n",
      "Epoch 35 of 100, loss: nan\n",
      "Epoch 36 of 100, loss: nan\n",
      "Epoch 37 of 100, loss: nan\n",
      "Epoch 38 of 100, loss: nan\n",
      "Epoch 39 of 100, loss: nan\n",
      "Epoch 40 of 100, loss: nan\n",
      "Epoch 41 of 100, loss: nan\n",
      "Epoch 42 of 100, loss: nan\n",
      "Epoch 43 of 100, loss: nan\n",
      "Epoch 44 of 100, loss: nan\n",
      "Epoch 45 of 100, loss: nan\n",
      "Epoch 46 of 100, loss: nan\n",
      "Epoch 47 of 100, loss: nan\n",
      "Epoch 48 of 100, loss: nan\n",
      "Epoch 49 of 100, loss: nan\n",
      "Epoch 50 of 100, loss: nan\n",
      "Epoch 51 of 100, loss: nan\n",
      "Epoch 52 of 100, loss: nan\n",
      "Epoch 53 of 100, loss: nan\n",
      "Epoch 54 of 100, loss: nan\n",
      "Epoch 55 of 100, loss: nan\n",
      "Epoch 56 of 100, loss: nan\n",
      "Epoch 57 of 100, loss: nan\n",
      "Epoch 58 of 100, loss: nan\n",
      "Epoch 59 of 100, loss: nan\n",
      "Epoch 60 of 100, loss: nan\n",
      "Epoch 61 of 100, loss: nan\n",
      "Epoch 62 of 100, loss: nan\n",
      "Epoch 63 of 100, loss: nan\n",
      "Epoch 64 of 100, loss: nan\n",
      "Epoch 65 of 100, loss: nan\n",
      "Epoch 66 of 100, loss: nan\n",
      "Epoch 67 of 100, loss: nan\n",
      "Epoch 68 of 100, loss: nan\n",
      "Epoch 69 of 100, loss: nan\n",
      "Epoch 70 of 100, loss: nan\n",
      "Epoch 71 of 100, loss: nan\n",
      "Epoch 72 of 100, loss: nan\n",
      "Epoch 73 of 100, loss: nan\n",
      "Epoch 74 of 100, loss: nan\n",
      "Epoch 75 of 100, loss: nan\n",
      "Epoch 76 of 100, loss: nan\n",
      "Epoch 77 of 100, loss: nan\n",
      "Epoch 78 of 100, loss: nan\n",
      "Epoch 79 of 100, loss: nan\n",
      "Epoch 80 of 100, loss: nan\n",
      "Epoch 81 of 100, loss: nan\n",
      "Epoch 82 of 100, loss: nan\n",
      "Epoch 83 of 100, loss: nan\n",
      "Epoch 84 of 100, loss: nan\n",
      "Epoch 85 of 100, loss: nan\n",
      "Epoch 86 of 100, loss: nan\n",
      "Epoch 87 of 100, loss: nan\n",
      "Epoch 88 of 100, loss: nan\n",
      "Epoch 89 of 100, loss: nan\n",
      "Epoch 90 of 100, loss: nan\n",
      "Epoch 91 of 100, loss: nan\n",
      "Epoch 92 of 100, loss: nan\n",
      "Epoch 93 of 100, loss: nan\n",
      "Epoch 94 of 100, loss: nan\n",
      "Epoch 95 of 100, loss: nan\n",
      "Epoch 96 of 100, loss: nan\n",
      "Epoch 97 of 100, loss: nan\n",
      "Epoch 98 of 100, loss: nan\n",
      "Epoch 99 of 100, loss: nan\n",
      "Epoch 100 of 100, loss: nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    hn = encoder.ema1.get_h0(torch.zeros(1))\n",
    "    losses = []\n",
    "    for batch, (batch_x, batch_y) in enumerate(loader):\n",
    "        batch_y_pred, hn = encoder(batch_x, hn)\n",
    "\n",
    "        batch_loss = loss_fn(batch_y_pred.squeeze(), batch_y)\n",
    "#         print(f'\\rBatch: {batch + 1} of {len(loader)}, loss: {batch_loss}', end='')\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "    loss = torch.stack(losses).mean()\n",
    "    loss.backward()\n",
    "    optmizer.step()\n",
    "    print(f'Epoch {epoch + 1} of {epochs}, loss: {loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
